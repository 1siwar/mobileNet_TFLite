# -*- coding: utf-8 -*-
"""mobileNet_classify.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zb-UQoQuTM9N0ITMtGWJoU7FYn6MYBC0
"""

#from google.colab import drive
#drive.mount("/content/drive/")

import tensorflow as tf 
import numpy as np
model="mobileNet_aware_q.tflite"
interpreter = tf.lite.Interpreter(model_path = model)
print("Model Loaded Successfully.", end="\n\n")
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
print("Input Shape:", input_details[0]['shape'])
print("Input Type:", input_details[0]['dtype'])
print("Output Shape:", output_details[0]['shape'])
print("Output Type:", output_details[0]['dtype'])
#---------------------------------------------------------------------------
interpreter.resize_tensor_input(input_details[0]['index'], (1,224,224,3))
interpreter.resize_tensor_input(output_details[0]['index'], (1, 1))
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
print("Input Shape:", input_details[0]['shape'])
print("Input Type:", input_details[0]['dtype'])
print("Output Shape:", output_details[0]['shape'])
print("Output Type:", output_details[0]['dtype'])

#--------------------------------------------------------------------------
test_dir = "test"
BATCH_SIZE = 32
IMG_SIZE = (224, 224)
test_dataset = tf.keras.utils.image_dataset_from_directory(test_dir,
                                                                 shuffle=False,
                                                                 batch_size=BATCH_SIZE,
                                                                 image_size=IMG_SIZE)
images_batch, label_batch = test_dataset.as_numpy_iterator().next()
imgs_batch = np.expand_dims(images_batch, axis=1)
test_imgs_numpy = np.array(imgs_batch, dtype=np.float32)
#-------------------------------------------------------------------------
#test_imgs_numpy = np.array(images_batch, dtype=np.float32)
prediction_classes=[]
for i in range(len(test_imgs_numpy)):
    interpreter.set_tensor(input_details[0]['index'], test_imgs_numpy[i])
    interpreter.invoke()
    tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])
    #print("Prediction results shape:", tflite_model_predictions.shape)
    prediction_classes.append(np.argmax(tflite_model_predictions, axis=1))

f=0
p=0
for i in range(len(prediction_classes)):
    if prediction_classes[i]==0 and label_batch[i]==0:
        f=f+1
    elif prediction_classes[i]==1 and label_batch[i]==1:
        p=p+1
print ("accuracy : {:.2f} %".format((p+f)/len(prediction_classes)*100))